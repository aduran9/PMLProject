all$coefficients - efit$coefficients
exit
q()
require(datasets)
dat(swiss)
data(swiss)
?swiss
library(datasets); data(swiss); require(stats); require(graphics)
pairs(swiss, panel = panel.smooth, main = "Swiss data", col = 3 + (swiss$Catholic > 50))
summary(lm(Fertility ~ . , data = swiss))
summary(lm(Fertility ~ . , data = swiss))$coefficents
summary(lm(Fertility ~ . , data = swiss))$coefficients
fit = lm(Fertility ~ Agriculture + factor(CatholicBin), data = swiss)
fit = lm(Fertility ~ Agriculture, data = swiss)
g1 = g
g1 = g1 +geom_abline(intercep = coef(fit)[1], slope = coef(fit)[2], size =2)
fit = lm(Fertility ~ Agriculture, data = swiss)
g1 = g1 +geom_abline(intercep = coef(fit)[1], slope = coef(fit)[2], size =2)
summary(fit)$coef
n <- 100; t <- rep(c(0, 1), c(n/2, n/2)); x <- c(runif(n/2), runif(n/2));
beta0 <- 0; beta1 <- 2; tau <- 1; sigma <- .2
y <- beta0 + x * beta1 + t * tau + rnorm(n, sd = sigma)
plot(x, y, type = "n", frame = FALSE)
abline(lm(y ~ x), lwd = 2)
abline(h = mean(y[1 : (n/2)]), lwd = 3)
abline(h = mean(y[(n/2 + 1) : n]), lwd = 3)
fit <- lm(y ~ x + t)
abline(coef(fit)[1], coef(fit)[2], lwd = 3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd = 3)
points(x[1 : (n/2)], y[1 : (n/2)], pch = 21, col = "black", bg = "lightblue", cex = 2)
points(x[(n/2 + 1) : n], y[(n/2 + 1) : n], pch = 21, col = "black", bg = "salmon", cex = 2)
library(rgl)
plot3d(x1, x2, y)
data(swiss); par(mfrow = c(2, 2))
fit <- lm(Fertility ~ . , data = swiss); plot(fit)
fit <- lm(Fertility ~ . , data = swiss); plot(fit)
fit <- lm(Fertility ~ . , data = swiss); plot(fit)
n <- 100; x <- c(10, rnorm(n)); y <- c(10, c(rnorm(n)))
plot(x, y, frame = FALSE, cex = 2, pch = 21, bg = "lightblue", col = "black")
abline(lm(y ~ x))
fit <- lm(y ~ x)
round(dfbetas(fit)[1 : 10, 2], 3)
round(dfbetas(fit2)[1 : 10, 2], 3)
n <- 100; x <- c(10, rnorm(n)); y <- c(10, c(rnorm(n)))
plot(x, y, frame = FALSE, cex = 2, pch = 21, bg = "lightblue", col = "black")
abline(lm(y ~ x))
fit <- lm(y ~ x)
round(dfbetas(fit)[1 : 10, 2], 3)
round(dfbetas(fit2)[1 : 10, 2], 3)
round(hatvalues(fit)[1 : 10], 3)
round(dfbetas(fit2)[1 : 10, 2], 3)
round(apply(betas, 1, sd), 5)
n <- 100; nosim <- 1000
x1 <- rnorm(n); x2 <- rnorm(n); x3 <- rnorm(n);
betas <- sapply(1 : nosim, function(i){
y <- x1 + rnorm(n, sd = .3)
c(coef(lm(y ~ x1))[2],
coef(lm(y ~ x1 + x2))[2],
coef(lm(y ~ x1 + x2 + x3))[2])
})
round(apply(betas, 1, sd), 5)
n <- 100; nosim <- 1000
x1 <- rnorm(n); x2 <- x1/sqrt(2) + rnorm(n) /sqrt(2)
x3 <- x1 * 0.95 + rnorm(n) * sqrt(1 - 0.95^2);
betas <- sapply(1 : nosim, function(i){
y <- x1 + rnorm(n, sd = .3)
c(coef(lm(y ~ x1))[2],
coef(lm(y ~ x1 + x2))[2],
coef(lm(y ~ x1 + x2 + x3))[2])
})
round(apply(betas, 1, sd), 5)
library(swirl)
swirl()
swirl()
swirl()
6
dim(InsectSprays)
head(InsectSprays, 15)
sA
summary(InsectSprays[,2])
sapply(InsectSprays,class)
fit <- lm(count ~ spray, InsectSprays)
omnitest(correctExpr='summary(fit)$coef')
summary(fit)$coef
est <- summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit <- lm(count ~ spray - 1, InsectSprays)
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray,"C")
fit2 <- lm(count ~ spray2, InsectSprays)
summary(fit2)$coef
mean(sC)
(fit$coef[2]-fit$coef[3])/1.6011
dim(hunger)
948
names(hunger)
fit <- lm(hunger$Numeric ~ hunger$Year)
summary(fit)$coef
lmF <- lm(hunger$Numeric[hunger$Sex=="Female"] ~ hunger$Year[hunger$Sex=="Female"])
lmM <- lm(hunger$Numeric[hunger$Sex=="Male"] ~ hunger$Year[hunger$Sex=="Male"])
swirl()
lmBoth <- lm(hunger$Numeric ~ hunger$Year + hunger$Sex)
summary(lmBoth)
lmInter <- lm(hunger$Numeric ~ hunger$Year + hunger$Sex + hunger$Year * hunger$Sex)
summary(lmInter)
fit <- lm(y ~ x, out2)
plot(fit, which=1)
fitno <- lm(y ~ x, out2[-1, ])
plot(fitno, which=1)
coef(fit)-coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy <- predict(fitno, out2)-predict(fit, out2)
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
install.packages("devtools")
devtools::install_github("jhudsl/collegeIncome")
library(collegeIncome)
data(college)
devtools::install_github("jhudsl/matahari")
library(matahari)
q()
library(swirl)
swirl()
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility ~ ., swiss)
vif(mdl)
mdl2 <- lm(Fertility ~ . -Examination, swiss)
vif(mdl2)
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
ravenData
mdl <- glm(ravenWinNum ~ ravenScore, binomial, ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
nxt()
View(hits)
class(hits[,'date'])
as.integer(head(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
mdl2 <- glm(simplystats ~ date, poisson, hits, offset=log(visits+1))
qpois(.95, mdl2$fitted.values[704])
q()
Library(caret)
library(caret)
install.packages("caret")
library(caret)
library(kernlab)
install.packages("kernlab")
library(kernlab)
data(spam)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
set.seed(32343)
q()
install.packages("ISLR")
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
dim(training)
dim(testing)
dim(testing); dim(testing)
dim(training); dim(testing)
featurePlot(x = training[, c("age", "education", "jobclass")], y = training$wage, plot = "pairs")
qplot(age, wage, data = training)
qplot(age, wage, coluor = jobclass, data = training)
qplot(age, wage, colour = jobclass, data = training)
qq <- qplot(age, wage, colour = education, data = training)
qq +geom_smooth(method ='lm', formula = y~x)
cutwage <- cut2(training$wage, g = 3)
cutwage <- cut2(training$wage, g=3)
cutWage <- cut2(training$wage, g = 3)
library(Hmisc)
cutWage <- cut2(training$wage, g = 3)
table(cutWage)
p1 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot"))
p1
p2 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot", "jitter"))
grid.arrange(p1, p2, ncol = 2)
p2 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot", "jitter"))
grid:arrange(p1, p2, ncol = 2)
grid::grid.arrange(p1, p2, ncol = 2)
gridExtra::grid.arrange(p1, p2, ncol = 2)
gridExtra::grid.arrange(p1, p2, ncol(2))
gridExtra::grid.arrange(p1, p2, ncol =2)
t1 <- table(cutWage, training$jobclass)
t1
prop.table(t1, 1)
qplot(wage, colour = education, data = training, geom = "density")
clear
clear()
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
erase.screen()
erase.screen()
clear
install.packages("nbBag")
install.packages("nbBag")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit <- train(Class ~ ., method = "rpart", data = training)
install.packages(e1071)
install.packages("e1071")
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(rattle)
install.packages("rattle")
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata = newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
library(ElemStatLearn)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
install.packages("~/R/win-library/ElemStatLearn_2015.6.26.2.tar.gz", repos = NULL, type = "source")
library(ElemStatLearn)
data(SAheart)
library(ElemStatLearn)
data((prostate))
data(prostate)
str(prostate)
small = prostate[1:5, ]
lm(lpsa ~ ., data = small)
library(quantmod)
from.dat <- as.Date("01/01/08", format = "%m/%d/%y")
to.dat <- as.Date("12/31/13", format"%m/%d/%y")
to.dat <- as.Date("12/31/13", format = "%m/%d/%y")
getSymbols("GOOG", src = "google", from = from.dat, to = to.dat)
getSymbols("GOOG", src = "google", from = from.dat, to = to.dat)
head(GOOG)
data("iris")
library(ggplot2)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
data(iris)
library(ggplot2)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
library(plyr)
library(dplyr)
library(randomForest)
library(rpart)
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(gbm)
library(lubridate)
library(forecast)
library(e1071)
library(mgcv)
library(nlme)
library(MASS)
library(elasticnet)
library(lars)
set.seed(19790811)
library(plyr)
library(dplyr)
library(randomForest)
library(rpart)
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(gbm)
library(lubridate)
library(forecast)
library(e1071)
library(mgcv)
library(nlme)
library(MASS)
library(elasticnet)
library(lars)
set.seed(19790811)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(gbm)
library(lubridate)
library(forecast)
library(e1071)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
library(gbm)
library(gbm)
install.packages("gbm")
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
library(gbm)
library(gbm)
detach("package:gbm", unload = TRUE)
library(gbm)
install.packages("gbm")
library(ElemStatLearn)
library(lattice)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(gbm)
library(lubridate)
library(forecast)
library(e1071)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(ElemStatLearn)
library(lattice)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(lubridate)
library(forecast)
library(e1071)
library(gbm)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
library(gbm)
library(ElemStatLearn)
library(lattice)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(lubridate)
library(forecast)
library(e1071)
library(gbm)
library(survival)
library(splines)
library(parallel)
library(plyr)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
rfvowel <- train(y ~ ., vowel.train, method = "rf")
predrf <- predict(rfvowel, newdata = vowel.test)
confusionMatrix(predrf, vowel.test$y)
gbmvowel <- train(y ~ ., vowel.train, method = "gbm", verbose = FALSE)
data(vowel.train)
data(vowel.test)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain, ]
testing = concrete[-inTrain, ]
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
cls
cls()
q()=
q()
library(caret)
library(rattle)
library(caret)
library(rattle)
getwd()
old.dir <- getwd()
setwd("./FProject")
getwd()
knitr::opts_chunk$set(echo = TRUE)
decisionTreeMod <- train(classe~., method="rpart", data=training_training_data)
q()
